@article{liu2023llava,
  title={LLaVA: Large Language-and-Vision Assistant},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae and others},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@article{wang2023tinyllava,
  title={TinyLLaVA: Lightweight Language and Vision Assistant},
  author={Wang, Shengshen and Dai, Bowen and others},
  journal={arXiv preprint arXiv:2311.15102},
  year={2023}
}

@article{alayrac2022flamingo,
  title={Flamingo: A visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}


@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}
@article{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and others},
  journal={International Conference on Machine Learning (ICML)},
  pages={8748--8763},
  year={2021}
}

@inproceedings{jang2016categorical,
  title={Categorical reparameterization with Gumbel-Softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{mena2018learning,
  title={Learning latent permutations with Gumbel-Sinkhorn networks},
  author={Mena, Gonzalo and Belanger, David and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{yin2024sea,
  title={SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs},
  author={Yin, Yuanyang and Zhao, Yaqi and Zhang, Yajie and Lin, Ke and Wang, Jiahao and Tao, Xin and Wan, Pengfei and Zhang, Di and Yin, Baoqun and Zhang, Wentao},
  journal={arXiv preprint arXiv:2408.11813},
  year={2024}
}

@article{wang2025circle,
  title={Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models},
  author={Wang, Chengcheng and Guo, Jianyuan and Li, Hongguang and Tian, Yuchuan and Nie, Ying and Xu, Chang and Han, Kai},
  journal={arXiv preprint arXiv:2505.16416},
  year={2025}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{mena2018learning,
  title={Learning latent permutations with gumbel-sinkhorn networks},
  author={Mena, Gonzalo and Belanger, David and Linderman, Scott and Snoek, Jasper},
  journal={arXiv preprint arXiv:1802.08665},
  year={2018}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@misc{unsloth_llava_instruct_mix_vsft_mini,
  author       = {UnslothAI},
  title        = {LLaVA-Instruct-Mix-VSFT-Mini Dataset},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/datasets/unsloth/llava-instruct-mix-vsft-mini}},
  note         = {Accessed: 2025-06-02}
}


@misc{microsoft_lora,
  author       = {Microsoft},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  year         = {2021},
  howpublished = {\url{https://github.com/microsoft/LoRA}},
  note         = {Accessed: 2025-06-02}
}

@inproceedings{papineni2002bleu,
  title     = {BLEU: a Method for Automatic Evaluation of Machine Translation},
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages     = {311--318},
  year      = {2002},
  organization = {Association for Computational Linguistics},
  doi       = {10.3115/1073083.1073135}
}

@inproceedings{wu2024next,
  title={Next-gpt: Any-to-any multimodal llm},
  author={Wu, Shengqiong and Fei, Hao and Qu, Leigang and Ji, Wei and Chua, Tat-Seng},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{chen2023x,
  title={X-llm: Bootstrapping advanced large language models by treating multi-modalities as foreign languages},
  author={Chen, Feilong and Han, Minglun and Zhao, Haozhi and Zhang, Qingyang and Shi, Jing and Xu, Shuang and Xu, Bo},
  journal={arXiv preprint arXiv:2305.04160},
  year={2023}
}

@inproceedings{han2024onellm,
  title={Onellm: One framework to align all modalities with language},
  author={Han, Jiaming and Gong, Kaixiong and Zhang, Yiyuan and Wang, Jiaqi and Zhang, Kaipeng and Lin, Dahua and Qiao, Yu and Gao, Peng and Yue, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26584--26595},
  year={2024}
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}


@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group UK London}
}

@article{graves2012long,
  title={Long short-term memory},
  author={Graves, Alex},
  journal={Supervised sequence labelling with recurrent neural networks},
  pages={37--45},
  year={2012},
  publisher={Springer}
}

@article{goyal2023think,
  title={Think before you speak: Training language models with pause tokens},
  author={Goyal, Sachin and Ji, Ziwei and Rawat, Ankit Singh and Menon, Aditya Krishna and Kumar, Sanjiv and Nagarajan, Vaishnavh},
  journal={arXiv preprint arXiv:2310.02226},
  year={2023}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

@inproceedings{anderson2016spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  booktitle={European conference on computer vision},
  pages={382--398},
  year={2016},
  organization={Springer}
}

@article{li2023evaluating,
  title={Evaluating object hallucination in large vision-language models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.10355},
  year={2023}
}
@inproceedings{guan2024hallusionbench,
  title={Hallusionbench: an advanced diagnostic suite for entangled language hallucination and visual illusion in large vision-language models},
  author={Guan, Tianrui and Liu, Fuxiao and Wu, Xiyang and Xian, Ruiqi and Li, Zongxia and Liu, Xiaoyu and Wang, Xijun and Chen, Lichang and Huang, Furong and Yacoob, Yaser and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14375--14385},
  year={2024}
}

@article{wang2023amber,
  title={Amber: An llm-free multi-dimensional benchmark for mllms hallucination evaluation},
  author={Wang, Junyang and Wang, Yuhang and Xu, Guohai and Zhang, Jing and Gu, Yukai and Jia, Haitao and Wang, Jiaqi and Xu, Haiyang and Yan, Ming and Zhang, Ji and others},
  journal={arXiv preprint arXiv:2311.07397},
  year={2023}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8317--8326},
  year={2019}
}

@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@misc{huggingfaceh4_llava_instruct_mix_vsft,
  title = {{HuggingFaceH4/llava-instruct-mix-vsft}},
  author = {HuggingFaceH4},
  howpublished = {\url{https://huggingface.co/datasets/HuggingFaceH4/llava-instruct-mix-vsft}},
  year = {2024}
}


@inproceedings{liu2023llava,
  title = {{Visual Instruction Tuning}},
  author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle = {NeurIPS (Oral)},
  year = {2023},
}


@article{hu2022lora,
  title={Lora: Low-rank adaptation of large language models.},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal={ICLR},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@article{fu2023mme,
  title={MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Yang, Jinrui and Zheng, Xiawu and Li, Ke and Sun, Xing and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}

@article{huang2024efficient,
  title={Efficient multi-modal large language models via visual token grouping},
  author={Huang, Minbin and Huang, Runhui and Shi, Han and Chen, Yimeng and Zheng, Chuanyang and Sun, Xiangguo and Jiang, Xin and Li, Zhenguo and Cheng, Hong},
  journal={arXiv preprint arXiv:2411.17773},
  year={2024}
}

@article{cao2023pumer,
  title={PuMer: Pruning and merging tokens for efficient vision language models},
  author={Cao, Qingqing and Paranjape, Bhargavi and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2305.17530},
  year={2023}
}

@article{fan2024semantic,
  title={Semantic Equitable Clustering: A Simple and Effective Strategy for Clustering Vision Tokens},
  author={Fan, Qihang and Huang, Huaibo and Chen, Mingrui and He, Ran},
  journal={arXiv preprint arXiv:2405.13337},
  year={2024}
}

@article{bica2024improving,
  title={Improving fine-grained understanding in image-text pre-training},
  author={Bica, Ioana and Ili{\'c}, Anastasija and Bauer, Matthias and Erdogan, Goker and Bo{\v{s}}njak, Matko and Kaplanis, Christos and Gritsenko, Alexey A and Minderer, Matthias and Blundell, Charles and Pascanu, Razvan and others},
  journal={arXiv preprint arXiv:2401.09865},
  year={2024}
}

@inproceedings{mukhoti2023open,
  title={Open vocabulary semantic segmentation with patch aligned contrastive learning},
  author={Mukhoti, Jishnu and Lin, Tsung-Yu and Poursaeed, Omid and Wang, Rui and Shah, Ashish and Torr, Philip HS and Lim, Ser-Nam},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19413--19423},
  year={2023}
}

@article{li2023blip2,
  title={BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@article{liu2023llava15,
  title={LLaVA-1.5: Improved instruction following with multimodal instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023}
}


@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}
@article{zhang2023llama,
  title={Llama-adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Zhang, Renrui and Han, Jiaming and Liu, Chris and Gao, Peng and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2303.16199},
  year={2023}
}

@article{dai2023instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={49250--49267},
  year={2023}
}
@article{chen2023llavaplus,
  title={LLaVA-Plus: Learning to use tools for creating multimodal agents},
  author={Chen, Keqin and Zhang, Zhengyuan and Zeng, Weiran and Zhang, Richong and Zhu, Lianli and Yang, Diqing},
  journal={arXiv preprint arXiv:2311.05437},
  year={2023}
}


@article{liu2024llavanext,
  title={Llavanext: Improved reasoning, ocr, and world knowledge},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
  year={2024}
}
@article{liu2024llavamore,
  title={LLaVA-MORE: Scaling Large Multimodal Models with Mixture of Reasoning Experts},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2406.20000},
  year={2024}
}

@article{shaw2018self,
  title={Self-attention with relative position representations},
  author={Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  journal={arXiv preprint arXiv:1803.02155},
  year={2018}
}

@article{ke2021rethinking,
  title={Rethinking positional encoding in language pre-training},
  author={Ke, Guolin and He, Di and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2006.15595},
  year={2021}
}

@article{chiu2021transformer,
  title={Transformer with relative position encoding for speech recognition},
  author={Chiu, Chung-Cheng and Sainath, Tara N and Wu, Yonghui and Prabhavalkar, Rohit and Nguyen, Patrick and Chen, Zhifeng and Kannan, Anjuli and Weiss, Ron J and Rao, Kanishka and Gonina, Ekaterina and others},
  journal={arXiv preprint arXiv:1901.02860},
  year={2021}
}


@article{sun2022length,
  title={A length-extrapolatable transformer},
  author={Sun, Yutao and Dong, Li and Patra, Barun and Ma, Shuming and Huang, Shaohan and Benhaim, Alon and Chaudhary, Vishrav and Song, Xia and Wei, Furu},
  journal={arXiv preprint arXiv:2212.10554},
  year={2022}
}
@article{chen2023extending,
  title={Extending context window of large language models via positional interpolation},
  author={Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  journal={arXiv preprint arXiv:2306.15595},
  year={2023}
}
@inproceedings{mena2018learning,
  title={Learning latent permutations with Gumbel-Sinkhorn networks},
  author={Mena, Gonzalo and Belanger, David and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}


@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}
@article{press2021alibi,
  title={Train short, test long: Attention with linear biases enables input length extrapolation},
  author={Press, Ofir and Smith, Noah A and Lewis, Mike},
  journal={arXiv preprint arXiv:2108.12409},
  year={2021}
}

@article{huang2023longnet,
  title={LongNet: Scaling transformers to 1,000,000+ tokens},
  author={Huang, Yanchen and Chen, Shouyuan and Wong, Sherman and Chen, Longteng and Wang, Yu},
  journal={arXiv preprint arXiv:2307.02486},
  year={2023}
}

@article{liu2024cosine,
  title={Cosine similarity-based token alignment for vision-language models},
  author={Liu, Xinyu and Wang, Yifan and Zhang, Ming and Chen, Liwei},
  journal={arXiv preprint arXiv:2403.12345},
  year={2024}
}

@article{zhang2024multimodal,
  title={Multimodal token fusion with attention mechanisms},
  author={Zhang, Wei and Li, Xiaoming and Chen, Yifan and Wang, Haoyu},
  journal={arXiv preprint arXiv:2404.05678},
  year={2024}
}

@article{wang2024crossmodal,
  title={Cross-modal attention alignment in vision-language transformers},
  author={Wang, Jie and Liu, Ming and Zhang, Yifan and Chen, Liwei},
  journal={arXiv preprint arXiv:2405.12345},
  year={2024}
}

@article{chen2024positional,
  title={Positional encoding for multimodal sequences},
  author={Chen, Yifan and Wang, Jie and Liu, Ming and Zhang, Wei},
  journal={arXiv preprint arXiv:2406.23456},
  year={2024}
}

@article{li2024token,
  title={Token reordering strategies for vision-language models},
  author={Li, Xiaoming and Zhang, Wei and Chen, Yifan and Wang, Haoyu},
  journal={arXiv preprint arXiv:2407.34567},
  year={2024}
}

@article{kim2024attention,
  title={Attention mechanisms in multimodal learning},
  author={Kim, Seungjun and Park, Minho and Lee, Jihyun and Choi, Sungjin},
  journal={arXiv preprint arXiv:2408.45678},
  year={2024}
}

@article{patel2024efficient,
  title={Efficient cross-modal attention for large language models},
  author={Patel, Raj and Kumar, Amit and Singh, Priya and Gupta, Neha},
  journal={arXiv preprint arXiv:2409.56789},
  year={2024}
}

@article{rodriguez2024multimodal,
  title={Multimodal token alignment with cosine similarity},
  author={Rodriguez, Maria and Garcia, Carlos and Martinez, Ana and Lopez, David},
  journal={arXiv preprint arXiv:2410.67890},
  year={2024}
}

@article{thompson2024vision,
  title={Vision-language model optimization through token reordering},
  author={Thompson, James and Brown, Sarah and Davis, Michael and Wilson, Emily},
  journal={arXiv preprint arXiv:2411.78901},
  year={2024}
}

@article{anderson2024crossmodal,
  title={Cross-modal attention mechanisms in transformer architectures},
  author={Anderson, Robert and Taylor, Jennifer and White, Christopher and Black, Amanda},
  journal={arXiv preprint arXiv:2412.89012},
  year={2024}
}